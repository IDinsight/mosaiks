{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reload evaluation module\n",
    "# import importlib\n",
    "# import custom.evaluation\n",
    "# importlib.reload(custom.evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold #train_test_split, RepeatedKFold\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from custom.preprocessing import load_and_merge_data, preserve_geometry, _add_shrid_to_mosaiks, _merge_mosaiks_and_secc\n",
    "from custom.shrug_data import lengthen_shapefile_ID_names, load_shrug_shapefiles, load_shrug_secc\n",
    "from custom.evaluation import show_results, plot_prediction_maps\n",
    "from custom.mosaiks_data import load_mosaiks_data\n",
    "from custom.utils import load_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%pyinstrument\n",
    "gdf = load_and_merge_data()\n",
    "# takes ~ 2.5mins on EC2 t2.2xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target\n",
    "y_name = \"secc_pov_rate_rural\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with unavailable target\n",
    "gdf_clean = gdf.dropna(subset=y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select list of columns to drop from the data so only features and target are left\n",
    "shrug_key_cols = [\n",
    "    \"pc11_state_id\",\n",
    "    \"pc11_district_id\",\n",
    "    \"pc11_subdistrict_id\",\n",
    "    \"pc11_village_id\",\n",
    "    \"tv_name\",\n",
    "    \"shrid\",\n",
    "    \"pc11_v_uid\",\n",
    "    \"geometry\",\n",
    "    \"geometry_village\"\n",
    "]\n",
    "geo_cols = [\"Lat\", \"Lon\"] + shrug_key_cols\n",
    "\n",
    "shrug_secc_cols = [\n",
    "    \"shrid\",\n",
    "    \"secc_inc_cultiv_share\",\n",
    "    \"nco2d_cultiv_share\",\n",
    "    \"secc_cons_pc_rural\",\n",
    "    \"secc_cons_pc_urban\",\n",
    "    \"secc_pov_rate_rural\",\n",
    "    \"secc_pov_rate_urban\",\n",
    "    \"secc_pov_rate_tend_rural\",\n",
    "    \"secc_pov_rate_tend_urban\",\n",
    "    \"num_members_mean_rural\",\n",
    "    \"num_members_mean_urban\",\n",
    "]\n",
    "shrug_secc_cols.remove(y_name)\n",
    "\n",
    "cols_to_drop = list(shrug_secc_cols) + geo_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features and target\n",
    "X = gdf_clean.drop(cols_to_drop + [y_name], axis=1)\n",
    "y = gdf_clean[y_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouped train-test split: making sure that datapoints from the same village don't get split across train and test datasets (to avoid leakage).\n",
    "\n",
    "Can change grouping variable to larger scale if needed (e.g. unique subdistrict IDs, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose train/test indices\n",
    "grouping_var = \"pc11_v_uid\"\n",
    "splitter = GroupShuffleSplit(test_size=0.20, n_splits=1, random_state=0)\n",
    "split = splitter.split(gdf_clean, groups=gdf_clean[grouping_var])\n",
    "train_index, test_index = list(split)[0]\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    X.iloc[train_index],\n",
    "    X.iloc[test_index],\n",
    "    y.iloc[train_index],\n",
    "    y.iloc[test_index],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model A\n",
    "Datapoints = latlong points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge()\n",
    "model.fit(X_train, y_train) #, sample_weight=y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- target distribution\n",
    "- optimise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # or with parameter search (grouped k-fold)\n",
    "\n",
    "# group_kfold = GroupKFold(n_splits=5)\n",
    "# cv_grouped = group_kfold.split(X, y, gdf_clean[grouping_var])\n",
    "\n",
    "# model = RidgeCV(alphas=[0.01, 1, 10], cv=cv_grouped)\n",
    "# model.fit(X_train, y_train, sample_weight=y_train)\n",
    "\n",
    "# # summarize chosen configuration\n",
    "# print('alpha: %f' % model.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the trained model to make predictions in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(y_test, y_pred, file_name=\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scaled = ((y_pred - 0.15) / (0.7 - 0.15))\n",
    "show_results(y_test, y_pred_scaled, file_name=\"results_scaled\", line=False, title=\"Scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select dataframe with only test target and location data\n",
    "gdf_clean_test_y = gdf_clean.iloc[test_index][geo_cols + [y_name]]\n",
    "\n",
    "# add predicted values\n",
    "gdf_clean_test_y.loc[:, \"predicted\"] = y_pred\n",
    "gdf_clean_test_y.loc[:, \"predicted_scaled\"] = y_pred_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_maps(gdf_clean_test_y, y_name, \"predicted\", False, 0, 1, \"points_prediction_map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate to `Subdistricts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total test datapoints: \", gdf_clean_test_y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_shapes = load_shrug_shapefiles(level=\"subdistrict\")\n",
    "sd_shapes[\"geometry_subdistrict\"] = sd_shapes[\"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_clean_test_y_subdistricts = gdf_clean_test_y.sjoin(sd_shapes)\n",
    "\n",
    "# change default geometry to subdistricts (for plotting)\n",
    "gdf_clean_test_y_subdistricts[\"geometry_point\"] = gdf_clean_test_y_subdistricts[\"geometry\"]\n",
    "gdf_clean_test_y_subdistricts[\"geometry\"] = gdf_clean_test_y_subdistricts[\"geometry_subdistrict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdistrict_ys = gdf_clean_test_y_subdistricts.groupby(\n",
    "    [\n",
    "        \"pc11_state_id\",\n",
    "        \"pc11_district_id\",\n",
    "        \"pc11_subdistrict_id\"\n",
    "    ],\n",
    "    as_index=False,\n",
    ")[[y_name, \"predicted\"]].mean()\n",
    "print(\"Datapoints with unique subdistricts: \", subdistrict_ys.shape[0])\n",
    "\n",
    "show_results(subdistrict_ys[y_name], subdistrict_ys[\"predicted\"], file_name=\"results_subdistricts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_maps(gdf_clean_test_y_subdistricts, y_name, \"predicted\", False, 0, 1, \"subdistricts_prediction_map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarise poverty levels using quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarise target using quantiles\n",
    "gdf_clean_test_y_subdistricts.loc[:, \"target_binarised\"] = pd.qcut(gdf_clean_test_y_subdistricts[y_name], q=2, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_clean_test_y_subdistricts[y_name+\"top_20_perc\"] = (pd.qcut(gdf_clean_test_y_subdistricts[y_name], q=5, labels=False) == 4) * 1\n",
    "gdf_clean_test_y_subdistricts[\"predicted_top_20_perc\"] = (pd.qcut(gdf_clean_test_y_subdistricts[\"predicted\"], q=5, labels=False) == 4) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_maps(gdf_clean_test_y_subdistricts, y_name+\"top_20_perc\", \"predicted_top_20_perc\", False, 0, 1, \"subdistricts_prediction_map_top20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 quadrant metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('nudge_up')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "142c193bf060635deeb675579e1db6ca9d9f29c8a237f64acc594fb64723fb97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
