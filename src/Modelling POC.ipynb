{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold #train_test_split, RepeatedKFold\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "from custom.preprocessing import load_and_merge_data, preserve_geometry, _add_shrid_to_mosaiks, _merge_mosaiks_and_secc\n",
    "from custom.shrug_data import lengthen_shapefile_ID_names, load_shrug_shapefiles, load_shrug_secc\n",
    "from custom.evaluation import show_results, plot_prediction_maps\n",
    "from custom.mosaiks_data import load_mosaiks_data\n",
    "from custom.utils import load_gdf, latlon_df_to_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/home/jovyan/ds_nudge_up/data/\"\n",
    "mosaiks_path = DATA_ROOT+\"/01_preprocessed/mosaiks_features/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mosaiks features (with latlons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_label = \"_1km_v1024_L8\"\n",
    "# filename = 'mosaiks_2013_L8_0.005b_all_points.parquet.gzip'\n",
    "\n",
    "data_label = \"_3km_v1024_L8\"\n",
    "filename = 'mosaiks_2013_L8_0.015b_all_points.parquet.gzip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94392, 1027)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mosaiks_features = pd.read_parquet(mosaiks_path+filename)\n",
    "mosaiks_features_gdf = latlon_df_to_gdf(mosaiks_features)\n",
    "mosaiks_features_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86382, 1027)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mosaiks_features_gdf = mosaiks_features_gdf.dropna()\n",
    "mosaiks_features_gdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHRUG geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrug_key_geoms = load_gdf(\n",
    "    \"01_preprocessed/SHRUG/shrug_pc11r_key_with_shapes\",\n",
    "    \"shrug_pc11r_key_with_shapes.shp\",\n",
    ")\n",
    "shrug_key_geoms = lengthen_shapefile_ID_names(shrug_key_geoms)\n",
    "shrug_key_geoms = preserve_geometry(shrug_key_geoms, level=\"village\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHRUG SECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrug_secc = load_shrug_secc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Mosaiks featues and SECC target via village shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiks_features_gdf = _add_shrid_to_mosaiks(mosaiks_features_gdf, shrug_key_geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = _merge_mosaiks_and_secc(mosaiks_features_gdf, shrug_secc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## old\n",
    "# gdf = load_and_merge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del shrug_key_geoms\n",
    "del shrug_secc\n",
    "del mosaiks_features_gdf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target\n",
    "y_name = \"secc_pov_rate_rural\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with unavailable target\n",
    "gdf_clean = gdf.dropna(subset=y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select list of columns to drop from the data so only features and target are left\n",
    "shrug_key_cols = [\n",
    "    \"pc11_state_id\",\n",
    "    \"pc11_district_id\",\n",
    "    \"pc11_subdistrict_id\",\n",
    "    \"pc11_village_id\",\n",
    "    \"tv_name\",\n",
    "    \"shrid\",\n",
    "    \"pc11_v_uid\",\n",
    "    \"geometry\",\n",
    "    \"geometry_village\"\n",
    "]\n",
    "geo_cols = [\"lat\", \"lon\"] + shrug_key_cols\n",
    "\n",
    "shrug_secc_cols = [\n",
    "    \"shrid\",\n",
    "    \"secc_inc_cultiv_share\",\n",
    "    \"nco2d_cultiv_share\",\n",
    "    \"secc_cons_pc_rural\",\n",
    "    \"secc_cons_pc_urban\",\n",
    "    \"secc_pov_rate_rural\",\n",
    "    \"secc_pov_rate_urban\",\n",
    "    \"secc_pov_rate_tend_rural\",\n",
    "    \"secc_pov_rate_tend_urban\",\n",
    "    \"num_members_mean_rural\",\n",
    "    \"num_members_mean_urban\",\n",
    "]\n",
    "shrug_secc_cols.remove(y_name)\n",
    "\n",
    "cols_to_drop = list(shrug_secc_cols) + geo_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features and target\n",
    "X = gdf_clean.drop(cols_to_drop + [y_name], axis=1)\n",
    "y = gdf_clean[y_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouped train-test split: making sure that datapoints from the same village don't get split across train and test datasets (to avoid leakage).\n",
    "\n",
    "Can change grouping variable to larger scale if needed (e.g. unique subdistrict IDs, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose train/test indices\n",
    "grouping_var = \"pc11_v_uid\"\n",
    "splitter = GroupShuffleSplit(test_size=0.20, n_splits=1, random_state=0)\n",
    "split = splitter.split(gdf_clean, groups=gdf_clean[grouping_var])\n",
    "train_index, test_index = list(split)[0]\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    X.iloc[train_index],\n",
    "    X.iloc[test_index],\n",
    "    y.iloc[train_index],\n",
    "    y.iloc[test_index],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model A\n",
    "Datapoints = latlong points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge()\n",
    "model.fit(X_train, y_train) #, sample_weight=y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- target distribution\n",
    "- optimise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # or with parameter search (grouped k-fold)\n",
    "\n",
    "# group_kfold = GroupKFold(n_splits=5)\n",
    "# cv_grouped = group_kfold.split(X, y, gdf_clean[grouping_var])\n",
    "\n",
    "# model = RidgeCV(alphas=[0.01, 1, 10], cv=cv_grouped)\n",
    "# model.fit(X_train, y_train, sample_weight=y_train)\n",
    "\n",
    "# # summarize chosen configuration\n",
    "# print('alpha: %f' % model.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the trained model to make predictions in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(y_test, y_pred, file_name=\"scatter\"+data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max = 0.1, 0.6\n",
    "y_pred_scaled = ((y_pred - min) / (max - min))\n",
    "show_results(y_test, y_pred_scaled, file_name=\"scatter_scaled\"+data_label, line=False, title=\"Scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select dataframe with only test target and location data\n",
    "gdf_clean_test_y = gdf_clean.iloc[test_index][geo_cols + [y_name]]\n",
    "\n",
    "# add predicted values\n",
    "gdf_clean_test_y.loc[:, \"predicted\"] = y_pred\n",
    "gdf_clean_test_y.loc[:, \"predicted_scaled\"] = y_pred_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_maps(gdf_clean_test_y, y_name, \"predicted\", False, 0, 1, \"maps_points\"+data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate to `Subdistricts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total test datapoints: \", gdf_clean_test_y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_shapes = load_shrug_shapefiles(level=\"subdistrict\")\n",
    "sd_shapes[\"geometry_subdistrict\"] = sd_shapes[\"geometry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_clean_test_y_subdistricts = gdf_clean_test_y.sjoin(sd_shapes)\n",
    "\n",
    "# change default geometry to subdistricts (for plotting)\n",
    "gdf_clean_test_y_subdistricts[\"geometry_point\"] = gdf_clean_test_y_subdistricts[\"geometry\"]\n",
    "gdf_clean_test_y_subdistricts[\"geometry\"] = gdf_clean_test_y_subdistricts[\"geometry_subdistrict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdistrict_ys = gdf_clean_test_y_subdistricts.groupby(\n",
    "    [\n",
    "        \"pc11_state_id\",\n",
    "        \"pc11_district_id\",\n",
    "        \"pc11_subdistrict_id\"\n",
    "    ],\n",
    "    as_index=False,\n",
    ")[[y_name, \"predicted\"]].mean()\n",
    "print(\"Datapoints with unique subdistricts: \", subdistrict_ys.shape[0])\n",
    "\n",
    "show_results(subdistrict_ys[y_name], subdistrict_ys[\"predicted\"], file_name=\"scatter_subdistricts\"+data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_maps(gdf_clean_test_y_subdistricts, y_name, \"predicted\", False, 0, 1, \"maps_sd\"+data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 20% poorest subdistricts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_clean_test_y_subdistricts[y_name+\"top_20_perc\"] = (pd.qcut(gdf_clean_test_y_subdistricts[y_name], q=5, labels=False) == 4) * 1\n",
    "gdf_clean_test_y_subdistricts[\"predicted_top_20_perc\"] = (pd.qcut(gdf_clean_test_y_subdistricts[\"predicted\"], q=5, labels=False) == 4) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_maps(gdf_clean_test_y_subdistricts, y_name+\"top_20_perc\", \"predicted_top_20_perc\", False, 0, 1, \"maps_sd_top20\"+data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under construction: 4 quadrant metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_top_quintile = np.percentile(y_pred, [80])[0]\n",
    "y_pred_is_top_quintile = list(y_pred > pred_top_quintile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_top_quintile = np.percentile(y_test, [80])[0]\n",
    "y_test_is_top_quintile = list(y_test > test_top_quintile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_pred, y=y_test, alpha=0.2)\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.axvline(pred_top_quintile, c=\"darkred\")\n",
    "plt.axhline(test_top_quintile, c=\"darkred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_is_NOT_top_quintile = [not b for b in y_pred_is_top_quintile]\n",
    "y_test_is_NOT_top_quintile = [not b for b in y_test_is_top_quintile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum(y_pred_is_top_quintile and y_test_is_top_quintile)\n",
    "FP = sum(y_pred_is_top_quintile and y_test_is_NOT_top_quintile)\n",
    "TN = sum(y_pred_is_NOT_top_quintile and y_test_is_NOT_top_quintile)\n",
    "FN = sum(y_pred_is_NOT_top_quintile and y_test_is_top_quintile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_array = confusion_matrix(y_test_is_top_quintile, y_pred_is_top_quintile)\n",
    "df_cm = pd.DataFrame(cm_array, [0,1], [0,1])\n",
    "\n",
    "precision = round(precision_score(y_test_is_top_quintile, y_pred_is_top_quintile), 3)\n",
    "recall = round(recall_score(y_test_is_top_quintile, y_pred_is_top_quintile), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_array.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "sns.heatmap(df_cm, annot=True, fmt='.5g', cbar=False)\n",
    "plt.title(f\"Precision: {precision}\\nRecall: {recall}\")\n",
    "plt.savefig(DATA_ROOT+\"/04_modeloutput/\"+\"confusion_matrix\"+data_label+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
