{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48754324",
   "metadata": {},
   "source": [
    "## How to Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e31fe7",
   "metadata": {},
   "source": [
    "0. Run `make setup-env` or just install `requirements.txt`\n",
    "\n",
    "1. Place the shrid polygons into the following folder:\n",
    "```\n",
    "    ðŸ“¦ data\n",
    "    â”— ðŸ“‚ 00_raw\n",
    "      â”— ðŸ“‚ SHRUG\n",
    "        â”£ ðŸ“‚ geometries_shrug-v1.5.samosa-open-polygons-shp\n",
    "```\n",
    "\n",
    "2. Run `python src/01_preprocess_create_mosaiks_points.py` or `make create-mosaiks-points`\n",
    "\n",
    "3. For MPC authentication, get your subscription key from [here](https://planetarycomputer.developer.azure-api.net/profile) and run `planetarycomputer configure` in terminal and paste is there. Further instructions [here](https://planetarycomputer.microsoft.com/docs/concepts/sas/#:~:text=data%20catalog.-,planetary%2Dcomputer%20Python%20package,-The%20planetary%2Dcomputer).\n",
    "\n",
    "3. Change the `DATA_ROOT` path to match your system and run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b9317-f3f8-48e2-a66b-6daa1dd9ff96",
   "metadata": {},
   "source": [
    "#### To Do:\n",
    "- Can we go older than 2013? No Landsat 7 on this endpoint...\n",
    "- Add column to output CSV to record why a no features where returned for a requested point\n",
    "- Read parameters from .yml/.json\n",
    "- Use Pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81f5f02-16ca-4208-87b4-2dde50c38ac7",
   "metadata": {
    "gather": {
     "logged": 1651174535306
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import dask_geopandas as dask_gpd\n",
    "from dask.distributed import Client\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9680b1a9-c78a-4f61-8470-d95e12407de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom.mosaiks_points import load_points_gdf\n",
    "\n",
    "from custom.mpc_imagery import (\n",
    "    sort_by_hilbert_distance,\n",
    "    filter_points_with_buffer,\n",
    "    fetch_least_cloudy_stac_items, \n",
    "    CustomDataset\n",
    ")\n",
    "from custom.models import featurize, RCF\n",
    "from custom.mosaiks_data import save_features_to_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9b4e1d-eabd-4456-b1ee-53a287b578eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action=\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1914d6d0-ea45-4976-b086-c2ed1e2652de",
   "metadata": {},
   "outputs": [],
   "source": [
    "RASTERIO_BEST_PRACTICES = dict(  # See https://github.com/pangeo-data/cog-best-practices\n",
    "    CURL_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\",\n",
    "    GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
    "    AWS_NO_SIGN_REQUEST=\"YES\",\n",
    "    GDAL_MAX_RAW_BLOCK_CACHE_SIZE=\"200000000\",\n",
    "    GDAL_SWATH_SIZE=\"200000000\",\n",
    "    VSI_CURL_CACHE_SIZE=\"200000000\",\n",
    ")\n",
    "os.environ.update(RASTERIO_BEST_PRACTICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d0b889-5c8b-47f4-89f6-079f2b04a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/home/jovyan/ds_nudge_up/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838705cb-c589-4014-a8a1-3b38194c5199",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b45f4e-9a8d-4fa9-a7ba-418cae804b62",
   "metadata": {},
   "source": [
    "- Note: Earliest L8 imagery is April 2013 so we pick the least cloudy image from the 1 year window after this date. Latest imagery is March 2022, so we take 1 year window prior to this date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce55ed3-8fb4-4acb-8375-6729713c0867",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = \"2013_exact_3km_v4000_L8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69dea692-7930-4734-81e3-24319666640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite = \"landsat-8-c2-l2\" #\"sentinel-2-l2a\"\n",
    "resolution = 30\n",
    "bands = [\n",
    "    # \"SR_B1\", # Coastal/Aerosol Band (B1)\n",
    "    \"SR_B2\",  # Blue Band (B2)\n",
    "    \"SR_B3\",  # Green Band (B3)\n",
    "    \"SR_B4\",  # Red Band (B4)\n",
    "    \"SR_B5\",  # Near Infrared Band 0.8 (B5)\n",
    "    \"SR_B6\",  # Short-wave Infrared Band 1.6 (B6)\n",
    "    \"SR_B7\",  # Short-wave Infrared Band 2.2 (B7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a549fb5f-ce7e-4750-aa70-ed498f177266",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_start = \"2013-04-01\" #\"2021-04-01\" #\"2015-11-01\"\n",
    "search_end = \"2014-03-31\" #\"2022-03-31\" #\"2015-11-01\"\n",
    "# 1500m buffer results in 100x100px images for Landsat's 30m resolution\n",
    "BUFFER_DISTANCE = 1500\n",
    "NUM_FEATURES = 4000\n",
    "\n",
    "# for image fetching\n",
    "min_image_edge = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9b0ec-c334-4751-91c4-91dabff6a44a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load point coordinates to fetch images for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a806a2-1316-4f4a-a3f8-1458ed7f0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"{DATA_ROOT}/01_preprocessed/mosaiks_request_points/INDIA_SHRUG_request_points.csv\"\n",
    "points_gdf = load_points_gdf(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c6816fd-09bc-4c33-aab0-5a928b244881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. points loaded: 96167\n"
     ]
    }
   ],
   "source": [
    "NUM_POINTS = len(points_gdf)\n",
    "print(\"No. points loaded:\", NUM_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfbe92f3-2bcd-4016-8da3-40aa9665aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gdf = sort_by_hilbert_distance(points_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce2698-744c-4b85-829b-28fa16bc2902",
   "metadata": {},
   "source": [
    "Convert to DaskGeoDataFrame for parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebfd0c2e-78fe-45a9-99a4-13112f0da841",
   "metadata": {
    "gather": {
     "logged": 1651174537641
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NPARTITIONS = 250\n",
    "points_dgdf = dask_gpd.from_geopandas(points_gdf, npartitions=NPARTITIONS, sort=False)\n",
    "\n",
    "del points_gdf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef68b83-ce2e-4e70-908f-3e909337af04",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the imagery around each point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbab9c3f-7c4b-4960-a034-15fd4d135c48",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get image refs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d5c27d-bf7c-41b9-961b-95406b7e5e75",
   "metadata": {},
   "source": [
    "Get stac_item references to the least cloudy image that corresponds to each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e15da99-790c-49dc-8bd3-c8f67565675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/user/amirali1376@gmail.com/proxy/8787/status\n"
     ]
    }
   ],
   "source": [
    "with Client(n_workers=8) as client:\n",
    "    print(client.dashboard_link)\n",
    "\n",
    "    # `meta` is the expected output format: an empty df with correct column types\n",
    "    meta = points_dgdf._meta\n",
    "    meta = meta.assign(stac_item=pd.Series([], dtype=\"object\"))\n",
    "\n",
    "    points_gdf_with_stac = points_dgdf.map_partitions(\n",
    "        fetch_least_cloudy_stac_items, \n",
    "        satellite=satellite,\n",
    "        search_start=search_start,\n",
    "        search_end=search_end,\n",
    "        meta=meta)\n",
    "\n",
    "    points_gdf_with_stac = points_gdf_with_stac.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "499a66b8-0993-490b-a7b5-90baec4785cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the found STAC image ref to file\n",
    "points_gdf_with_stac.to_pickle(f\"{DATA_ROOT}/01_preprocessed/mosaiks_features/latlons_and_stacs_{data_label}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a58ce6f-9479-4aaf-9bf6-b2f83706dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_item_list = points_gdf_with_stac.stac_item.tolist()\n",
    "points_list = points_gdf_with_stac[[\"Lon\", \"Lat\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a816cb7-0c3c-4ab2-b1e4-84f6b8167a85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup PyTorch data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02239721-58fa-422c-8436-9503f6218c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(\n",
    "    points_list,\n",
    "    stac_item_list, \n",
    "    buffer=BUFFER_DISTANCE,\n",
    "    bands=bands,\n",
    "    resolution=resolution\n",
    ")\n",
    "\n",
    "batch_size = 1 # increase this?\n",
    "num_workers = os.cpu_count() # AWS can handle *2 since 32GB ram\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers, \n",
    "    collate_fn=lambda x: x,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f096c0-990c-49af-9367-f09c8d998269",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clear memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90655bb2-54fc-4355-b9a1-9f26b35bc0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1339"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del client\n",
    "del points_gdf_with_stac\n",
    "del stac_item_list\n",
    "# del points_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ac041-c732-4ca5-a233-ce4a066a8c21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf28b4c4-643d-4270-b3f7-0579a1a3e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images in dataloader:\n",
    "#     for image in images:\n",
    "#             if image is not None:\n",
    "#                 # print(image)\n",
    "#                 array = np.array(image[0][:3])\n",
    "#                 array = np.flip(array)\n",
    "#                 reshaped_array = np.swapaxes(array, 0, 2)\n",
    "#                 plt.imshow(reshaped_array)\n",
    "#                 plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4240994-4820-4a1b-a13c-836c2e592174",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define featurization model and apply to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b244448f-9b79-4c58-b779-5e8a4957c84e",
   "metadata": {
    "gather": {
     "logged": 1651174537496
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\") # change to \"cuda\" when using GPU\n",
    "MODEL = RCF(NUM_FEATURES).eval().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e03ed-cbfd-4dde-aaa7-2be27f19ffef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apply featurization to images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe45d2a-5dfb-4fc1-bf76-311d7bd2178e",
   "metadata": {},
   "source": [
    "Full image should be 100x100 pixels (3km^2 at 30m/px), but we can receive smaller images if an input point happens to be at the edge of a scene. To deal with these we crudely drop all images where the spatial dimensions aren't both greater than `min_image_edge` pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52822bf2-b16a-4c21-b00a-2dfd4666924b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d78e707ba454fadb421021d15bdd33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_all = np.full([NUM_POINTS, NUM_FEATURES], np.nan, dtype=float)\n",
    "\n",
    "i = 0\n",
    "end_index = 0\n",
    "for images in tqdm(dataloader):\n",
    "    for image in images:\n",
    "        if image is not None:\n",
    "            if image.shape[2] >= min_image_edge and image.shape[3] >= min_image_edge:\n",
    "                mosaiks_features = featurize(image, MODEL, DEVICE)\n",
    "                X_all[i] = mosaiks_features\n",
    "            else:\n",
    "                # if image size is too small\n",
    "                pass\n",
    "        else:\n",
    "            # if we do have not found an image for some point\n",
    "            pass\n",
    "        \n",
    "        # save to file every 10k points\n",
    "        if (i!=0 and i%10000==0) or i==NUM_POINTS:\n",
    "            start_index = end_index\n",
    "            end_index = i\n",
    "            X_chunk = X_all[start_index:end_index]\n",
    "\n",
    "            print(f\"Saving {start_index} to {end_index-1}...\")\n",
    "            \n",
    "            save_features_to_parquet(\n",
    "                array=X_chunk, \n",
    "                points_list=points_list, \n",
    "                start_index=start_index, \n",
    "                end_index=end_index, \n",
    "                output_folder_path=f\"{DATA_ROOT}/01_preprocessed/mosaiks_features/\", \n",
    "                filename_prefix=\"temp_\"+data_label,\n",
    "            )\n",
    "            \n",
    "            del X_chunk\n",
    "            gc.collect()\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42109715-ab05-4396-b82c-ab1a47fc6362",
   "metadata": {},
   "source": [
    "### Save to file (gzipped parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b067e-051f-41d2-b06d-c7bb3acf1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_features_to_parquet(\n",
    "    array=X_all, \n",
    "    points_list=points_list,\n",
    "    output_folder_path=f\"{DATA_ROOT}/01_preprocessed/mosaiks_features/\", \n",
    "    filename_prefix=data_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97737af9-511c-4d61-93c6-727d38274aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
