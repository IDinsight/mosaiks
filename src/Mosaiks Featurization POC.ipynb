{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48754324",
   "metadata": {},
   "source": [
    "## How to Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e31fe7",
   "metadata": {},
   "source": [
    "0. Run `make setup-env` or just install `requirements.txt`\n",
    "\n",
    "1. Place the shrid polygons into the following folder:\n",
    "```\n",
    "    ðŸ“¦ data\n",
    "    â”— ðŸ“‚ 00_raw\n",
    "      â”— ðŸ“‚ SHRUG\n",
    "        â”£ ðŸ“‚ geometries_shrug-v1.5.samosa-open-polygons-shp\n",
    "```\n",
    "\n",
    "2. Run `python src/01_preprocess_create_mosaiks_points.py` or `make create-mosaiks-points`\n",
    "\n",
    "3. For MPC authentication, get your subscription key from [here](https://planetarycomputer.developer.azure-api.net/profile) and run `planetarycomputer configure` in terminal and paste is there. Further instructions [here](https://planetarycomputer.microsoft.com/docs/concepts/sas/#:~:text=data%20catalog.-,planetary%2Dcomputer%20Python%20package,-The%20planetary%2Dcomputer).\n",
    "\n",
    "3. Change the `DATA_ROOT` path to match your system and run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b9317-f3f8-48e2-a66b-6daa1dd9ff96",
   "metadata": {},
   "source": [
    "#### To Do:\n",
    "- Can we go older than 2013?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81f5f02-16ca-4208-87b4-2dde50c38ac7",
   "metadata": {
    "gather": {
     "logged": 1651174535306
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import dask_geopandas as dask_gpd\n",
    "from dask.distributed import Client\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9680b1a9-c78a-4f61-8470-d95e12407de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom.mpc_imagery import (\n",
    "    sort_by_hilbert_distance, \n",
    "    filter_points_with_buffer,\n",
    "    fetch_least_cloudy_stac_items, \n",
    "    CustomDataset\n",
    ")\n",
    "from custom.models import featurize, RCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9b4e1d-eabd-4456-b1ee-53a287b578eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action=\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1914d6d0-ea45-4976-b086-c2ed1e2652de",
   "metadata": {},
   "outputs": [],
   "source": [
    "RASTERIO_BEST_PRACTICES = dict(  # See https://github.com/pangeo-data/cog-best-practices\n",
    "    CURL_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\",\n",
    "    GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
    "    AWS_NO_SIGN_REQUEST=\"YES\",\n",
    "    GDAL_MAX_RAW_BLOCK_CACHE_SIZE=\"200000000\",\n",
    "    GDAL_SWATH_SIZE=\"200000000\",\n",
    "    VSI_CURL_CACHE_SIZE=\"200000000\",\n",
    ")\n",
    "os.environ.update(RASTERIO_BEST_PRACTICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d0b889-5c8b-47f4-89f6-079f2b04a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/home/jovyan/ds_nudge_up/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9b0ec-c334-4751-91c4-91dabff6a44a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load point coordinates to fetch images for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad1d0ad",
   "metadata": {},
   "source": [
    "Load latlons from file and convert to GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d10cb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96167\n"
     ]
    }
   ],
   "source": [
    "points_df = pd.read_csv(f\"{DATA_ROOT}01_preprocessed/mosaiks_request_points/INDIA_SHRUG_request_points.csv\")\n",
    "points_gdf = gpd.GeoDataFrame(\n",
    "    points_df, \n",
    "    geometry=gpd.points_from_xy(\n",
    "        points_df['lon'], \n",
    "        points_df['lat']\n",
    "    ),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "del points_df\n",
    "\n",
    "print(points_gdf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3682b4f9-8808-4a02-80fe-a63b46fdbd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing, limit to 10 points\n",
    "# points_gdf = points_gdf.sample(10000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfbe92f3-2bcd-4016-8da3-40aa9665aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gdf = sort_by_hilbert_distance(points_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bbc1a96-34bf-4a1d-8f4f-d0c0cac8789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# points_gdf.plot(markersize=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce2698-744c-4b85-829b-28fa16bc2902",
   "metadata": {},
   "source": [
    "Convert to DaskGeoDataFrame for parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebfd0c2e-78fe-45a9-99a4-13112f0da841",
   "metadata": {
    "gather": {
     "logged": 1651174537641
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NPARTITIONS = 250\n",
    "points_dgdf = dask_gpd.from_geopandas(points_gdf, npartitions=NPARTITIONS, sort=False)\n",
    "\n",
    "del points_gdf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef68b83-ce2e-4e70-908f-3e909337af04",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the imagery around each point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbab9c3f-7c4b-4960-a034-15fd4d135c48",
   "metadata": {},
   "source": [
    "Get stac_item references to the least cloudy image that corresponds to each point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b45f4e-9a8d-4fa9-a7ba-418cae804b62",
   "metadata": {},
   "source": [
    "Note: Latest imagery is March 2022, so we take 1 year previous for our recent sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e15da99-790c-49dc-8bd3-c8f67565675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/user/amirali1376@gmail.com/proxy/8787/status\n"
     ]
    }
   ],
   "source": [
    "with Client(n_workers=8) as client:\n",
    "    print(client.dashboard_link)\n",
    "\n",
    "    # `meta` is the expected output format:\n",
    "    # an empty df with correct column types\n",
    "    meta = points_dgdf._meta\n",
    "    meta = meta.assign(stac_item=pd.Series([], dtype=\"object\"))\n",
    "\n",
    "    points_gdf_with_stac = points_dgdf.map_partitions(\n",
    "        fetch_least_cloudy_stac_items, \n",
    "        satellite=\"landsat-8-c2-l2\",\n",
    "        search_start=\"2013-01-01\", #\"2021-03-01\",\n",
    "        search_end=\"2013-12-31\", #\"2022-03-31\",\n",
    "        meta=meta)\n",
    "\n",
    "    points_gdf_with_stac = points_gdf_with_stac.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192a668-4df8-40f6-a9fa-db9f8a7f2315",
   "metadata": {},
   "source": [
    "Filter out points with no image found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a03c9ed-f0aa-48e8-9ce2-6dbea22743cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gdf_with_stac_clean = points_gdf_with_stac.dropna(subset=[\"stac_item\"])\n",
    "matched_stac_items = points_gdf_with_stac_clean.stac_item.tolist()\n",
    "matched_points_list = points_gdf_with_stac_clean[[\"lon\", \"lat\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c565a03d-423e-4564-8115-06da2399e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = len(points_gdf_with_stac_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a816cb7-0c3c-4ab2-b1e4-84f6b8167a85",
   "metadata": {},
   "source": [
    "Setup Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02239721-58fa-422c-8436-9503f6218c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_DISTANCE = 0.015 # results in 101x101 pixel images for Landsat's 30m resolution\n",
    "bands = [\n",
    "    # \"SR_B1\", # Coastal/Aerosol Band (B1)\n",
    "    \"SR_B2\",  # Blue Band (B2)\n",
    "    \"SR_B3\",  # Green Band (B3)\n",
    "    \"SR_B4\",  # Red Band (B4)\n",
    "    \"SR_B5\",  # Near Infrared Band 0.8 (B5)\n",
    "    \"SR_B6\",  # Short-wave Infrared Band 1.6 (B6)\n",
    "    \"SR_B7\",  # Short-wave Infrared Band 2.2 (B7)\n",
    "]\n",
    "resolution = 30\n",
    "\n",
    "dataset = CustomDataset(\n",
    "    matched_points_list, \n",
    "    matched_stac_items, \n",
    "    buffer=BUFFER_DISTANCE,\n",
    "    bands=bands,\n",
    "    resolution=resolution\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6cf8fa-df37-4ce8-8906-64aae377b28e",
   "metadata": {},
   "source": [
    "Setup PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d10d353-8c5f-4f04-81c7-2f2674b85e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 # increase this?\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=os.cpu_count(), # AWS can handle *2 since 32GB ram\n",
    "    collate_fn=lambda x: x,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ac041-c732-4ca5-a233-ce4a066a8c21",
   "metadata": {},
   "source": [
    "Inspect images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf28b4c4-643d-4270-b3f7-0579a1a3e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images in dataloader:\n",
    "#     for image in images:\n",
    "#         # print(image)\n",
    "#         array = np.array(image[0][:3])\n",
    "#         reshaped_array = np.swapaxes(array, 0, 2)\n",
    "#         plt.imshow(reshaped_array)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f096c0-990c-49af-9367-f09c8d998269",
   "metadata": {},
   "source": [
    "Clear memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90655bb2-54fc-4355-b9a1-9f26b35bc0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1516"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del points_gdf_with_stac\n",
    "del points_gdf_with_stac_clean\n",
    "del matched_stac_items\n",
    "# del matched_points_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4240994-4820-4a1b-a13c-836c2e592174",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define featurization model and apply to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b50f145-53cd-4ab1-999d-9d3015cea01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b244448f-9b79-4c58-b779-5e8a4957c84e",
   "metadata": {
    "gather": {
     "logged": 1651174537496
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\") # change to \"cuda\" when using GPU\n",
    "MODEL = RCF(NUM_FEATURES).eval().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e03ed-cbfd-4dde-aaa7-2be27f19ffef",
   "metadata": {},
   "source": [
    "### Apply featurization to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9b1a7d7-4fbb-4938-a78d-313784d8a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_image_edge = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44946923-f402-48da-aadb-edca9c7bec87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b92a07b75f34d8bb2bb772bcb94543a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_all = np.zeros((NUM_POINTS, NUM_FEATURES), dtype=float)\n",
    "\n",
    "i = 0\n",
    "for images in tqdm(dataloader):\n",
    "    for image in images:\n",
    "\n",
    "        if image is not None:\n",
    "            # A full image should be 36x36(?) pixels (i.e. ~1km^2 at a 30m/px spatial\n",
    "            # resolution), however we can receive smaller images if an input point\n",
    "            # happens to be at the edge of a scene. To deal with these we crudely \n",
    "            # drop all images where the spatial dimensions aren't both greater than 6 pixels.\n",
    "            if image.shape[2] >= min_image_edge and image.shape[3] >= min_image_edge:\n",
    "                mosaiks_features = featurize(image, MODEL, DEVICE)\n",
    "                x_all[i] = mosaiks_features\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass  # this happens if we do have not found an image for some point\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0748c-3744-4985-81e2-fb345342c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b0163-ddfa-4da1-83a8-8d3e01cc9526",
   "metadata": {},
   "source": [
    "### Convert to DF and add latlons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1086991-d2a6-46d8-b03e-76f0b3364f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [str(i) for i in range(NUM_FEATURES)]\n",
    "x_all_df = pd.DataFrame(x_all, columns=column_names)\n",
    "x_all_df.insert(0, \"Lat\", matched_points_list[:, 1])\n",
    "x_all_df.insert(1, \"Lon\", matched_points_list[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42109715-ab05-4396-b82c-ab1a47fc6362",
   "metadata": {},
   "source": [
    "### Save to file (parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92adf104-bbda-4d8a-8925-c28bac23e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = DATA_ROOT+\"/01_preprocessed/mosaiks_features/\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "filename = \"mosaiks_2013_0.015buffer_landsat8_INDIA_points_all\"\n",
    "x_all_df.to_parquet(output_path+filename+\".parquet.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8671ad36-0176-4458-8e21-77f986c82be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs\n",
    "\n",
    "# x_all_df_clean = x_all_df.dropna()\n",
    "# x_all_df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bd267-9460-4acd-b990-31911854fa10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
