{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {'col1': [1, 2, 3, 4], 'col2': [5, 6, 7, 8]}\n",
    "# df = dd.from_pandas(pd.DataFrame(data=d), npartitions=2)\n",
    "# dd.to_parquet(df=df,\n",
    "#               path='abfs://CONTAINER/FILE.parquet'\n",
    "#               storage_options={'account_name': 'ACCOUNT_NAME',\n",
    "#                                'account_key': 'ACCOUNT_KEY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BATCHED RUNNING. REQUIRES POINTS_GDF_WITH_STAC to start ####\n",
    "\n",
    "# def run_partitions(\n",
    "#     partitions: list,\n",
    "#     satellite_config: dict,\n",
    "#     featurization_config: dict,\n",
    "#     model: nn.Module,\n",
    "#     client: Client,\n",
    "#     mosaiks_folder_path: str = None,\n",
    "#     partition_ids: list = None,\n",
    "# ) -> list:\n",
    "#     \"\"\"Run partitions in batches of n_per_run and save the result for each partition\n",
    "#     to a parquet file. If a partition fails to be featurized, the partition ID is added\n",
    "#     to a list and returned at the end of the run.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     partitions : List of dataframes.\n",
    "#     satellite_config : Dictionary containing the satellite configuration.\n",
    "#     featurization_config : Dictionary containing the featurization parameters.\n",
    "#     model : PyTorch random convolutional feature model.\n",
    "#     client : Dask client.\n",
    "#     mosaiks_folder_path : Path to the folder where the mosaiks features should be saved.\n",
    "#     partition_ids : List of partition IDs corresponding to each partition in `partitions`.\n",
    "#         If None, the partition IDs will be inferred from the order of the\n",
    "#         partitions in the list. Default is None.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     failed_ids : List of partition IDs that failed to be featurized.\n",
    "#     \"\"\"\n",
    "\n",
    "#     n_per_run = featurization_config[\"dask\"][\"n_per_run\"]\n",
    "#     n_partitions = len(partitions)\n",
    "#     logging.info(f\"Running {n_partitions} partitions...\")\n",
    "\n",
    "#     if n_partitions < n_per_run:\n",
    "#         logging.info(\n",
    "#             f\"n_partitions is smaller than n_per_run. Running all {n_partitions} partitions.\"\n",
    "#         )\n",
    "#         n_per_run = n_partitions\n",
    "\n",
    "#     if partition_ids is None:\n",
    "#         partition_ids = list(range(n_partitions))\n",
    "\n",
    "#     mosaiks_column_names = [\n",
    "#         f\"mosaiks_{i}\" for i in range(featurization_config[\"model\"][\"num_features\"])\n",
    "#     ]\n",
    "\n",
    "#     failed_ids = []\n",
    "#     checkpoint_indices = np.arange(0, n_partitions + n_per_run, n_per_run)\n",
    "#     for p_start_id, p_end_id in zip(checkpoint_indices[:-1], checkpoint_indices[1:]):\n",
    "\n",
    "#         now = datetime.now().strftime(\"%d-%b %H:%M:%S\")\n",
    "#         logging.info(f\"{now} Running batch: {p_start_id} to {p_end_id - 1}\")\n",
    "\n",
    "#         batch_indices = list(range(p_start_id, p_end_id))\n",
    "#         batch_p_ids = [partition_ids[i] for i in batch_indices]\n",
    "#         batch_partitions = [partitions[i] for i in batch_indices]\n",
    "\n",
    "#         failed_ids += run_batch(\n",
    "#             partitions=batch_partitions,\n",
    "#             partition_ids=batch_p_ids,\n",
    "#             satellite_config=satellite_config,\n",
    "#             featurization_config=featurization_config,\n",
    "#             mosaiks_column_names=mosaiks_column_names,\n",
    "#             model=model,\n",
    "#             client=client,\n",
    "#             mosaiks_folder_path=mosaiks_folder_path,\n",
    "#         )\n",
    "\n",
    "#     return failed_ids\n",
    "\n",
    "\n",
    "# def run_batch(\n",
    "#     partitions: list,\n",
    "#     partition_ids: list,\n",
    "#     satellite_config: dict,\n",
    "#     featurization_config: dict,\n",
    "#     mosaiks_column_names: list,\n",
    "#     model: nn.Module,\n",
    "#     client: Client,\n",
    "#     mosaiks_folder_path: str,\n",
    "# ) -> list:\n",
    "#     \"\"\"\n",
    "#     Run a batch of partitions and save the result for each partition to a parquet file.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     partitions :List of dataframes to process.\n",
    "#     partition_ids : List containing IDs corresponding to the partitions passed (to be used\n",
    "#         for naming saved files and reference in case of failure).\n",
    "#     satellite_config : Dictionary containing the satellite configuration.\n",
    "#     featurization_config : Dictionary containing the featurization parameters.\n",
    "#     model : PyTorch random convolutional feature model.\n",
    "#     client : Dask client.\n",
    "#     mosaiks_folder_path : Path to the folder where the mosaiks features should be saved.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     failed_ids : List of partition labels that failed to be featurized.\n",
    "#     \"\"\"\n",
    "\n",
    "#     failed_ids = []\n",
    "#     delayed_dfs = []\n",
    "\n",
    "#     # collect futures\n",
    "#     for p_id, p in zip(partition_ids, partitions):\n",
    "#         str_id = str(p_id).zfill(3)  # makes 1 into '001'\n",
    "\n",
    "#         f = delayed_partition_run(\n",
    "#             df=p,\n",
    "#             satellite_config=satellite_config,\n",
    "#             featurization_config=featurization_config,\n",
    "#             mosaiks_column_names=mosaiks_column_names,\n",
    "#             model=model,\n",
    "#             dask_key_name=f\"features_{str_id}\",\n",
    "#         )\n",
    "#         delayed_dfs.append(f)\n",
    "\n",
    "#     # delayed -> futures -> collected results\n",
    "#     futures_dfs = client.compute(delayed_dfs)\n",
    "#     failed_ids = collect_results(\n",
    "#         futures_dfs=futures_dfs, mosaiks_folder_path=mosaiks_folder_path\n",
    "#     )\n",
    "\n",
    "#     # prep for next run\n",
    "#     client.restart()\n",
    "#     sleep(5)\n",
    "\n",
    "#     return failed_ids\n",
    "\n",
    "\n",
    "# def collect_results(futures_dfs: list, mosaiks_folder_path: str) -> list:\n",
    "#     \"\"\"\n",
    "#     Save computed dataframes to parquet files. If a partition fails to be featurized,\n",
    "#     the partition ID is added to a list.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     futures_dfs : List of futures containing the computed dataframes.\n",
    "#     mosaiks_folder_path : Path to the folder where the mosaiks features should be saved.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     failed_ids : List of partition IDs that failed to be featurized.\n",
    "#     \"\"\"\n",
    "\n",
    "#     failed_ids = []\n",
    "#     for f in as_completed(futures_dfs):\n",
    "#         try:\n",
    "#             df = f.result()\n",
    "#             utl.save_dataframe(\n",
    "#                 df=df, file_path=f\"{mosaiks_folder_path}/df_{f.key}.parquet.gzip\"\n",
    "#             )\n",
    "#         except Exception as e:\n",
    "#             f_key = f.key\n",
    "#             partition_id = int(f_key.split(\"features_\")[1])\n",
    "#             logging.info(f\"Partition {partition_id} failed. Error:\", e)\n",
    "#             failed_ids.append(partition_id)\n",
    "\n",
    "#     return failed_ids\n",
    "\n",
    "\n",
    "# def run_single_partition(\n",
    "#     partition: pd.DataFrame,\n",
    "#     satellite_config: dict,\n",
    "#     featurization_config: dict,\n",
    "#     model: nn.Module,\n",
    "#     client: Client,\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"Run featurization for a single partition. For testing.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     partition : Dataframe containing the data to featurize.\n",
    "#     satellite_config : Dictionary containing the satellite configuration.\n",
    "#     featurization_config : Dictionary containing the featurization parameters.\n",
    "#     model : PyTorch random convolutional feature model.\n",
    "#     client : Dask client.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     df : Dataframe containing the featurized data.\n",
    "#     \"\"\"\n",
    "\n",
    "#     mosaiks_column_names = [\n",
    "#         f\"mosaiks_{i}\" for i in range(featurization_config[\"model\"][\"num_features\"])\n",
    "#     ]\n",
    "\n",
    "#     f = delayed_partition_run(\n",
    "#         df=partition,\n",
    "#         satellite_config=satellite_config,\n",
    "#         featurization_config=featurization_config,\n",
    "#         mosaiks_column_names=mosaiks_column_names,\n",
    "#         model=model,\n",
    "#         dask_key_name=\"single_run\",\n",
    "#     )\n",
    "\n",
    "#     df_future = client.compute(f)\n",
    "#     for f in as_completed([df_future]):\n",
    "#         df = f.result()\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# @delayed\n",
    "# def delayed_partition_run(\n",
    "#     df: pd.DataFrame,\n",
    "#     satellite_config: dict,\n",
    "#     featurization_config: dict,\n",
    "#     mosaiks_column_names: list,\n",
    "#     model: nn.Module,\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"Run featurization for a single partition.\"\"\"\n",
    "\n",
    "#     data_loader = create_data_loader(\n",
    "#         points_gdf_with_stac=df,\n",
    "#         satellite_params=satellite_config,\n",
    "#         batch_size=featurization_config[\"model\"][\"batch_size\"],\n",
    "#     )\n",
    "\n",
    "#     X_features = create_features(\n",
    "#         dataloader=data_loader,\n",
    "#         n_features=featurization_config[\"model\"][\"num_features\"],\n",
    "#         n_points=len(df),\n",
    "#         model=model,\n",
    "#         device=featurization_config[\"model\"][\"device\"],\n",
    "#         min_image_edge=satellite_config[\"min_image_edge\"],\n",
    "#     )\n",
    "\n",
    "#     df = pd.DataFrame(\n",
    "#         data=X_features, index=df.index.copy(), columns=mosaiks_column_names\n",
    "#     )\n",
    "\n",
    "#     return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
