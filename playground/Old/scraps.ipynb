{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW - STACKSTAC call is in LatLon 4326 #########################\n",
    "# convert point latlons to image crs and create buffer using meters\n",
    "stac_crs = stac_item.properties[\"proj:epsg\"]\n",
    "proj_latlon_to_stac = pyproj.Transformer.from_crs(\n",
    "    4326, stac_crs, always_xy=True\n",
    ")\n",
    "x_utm, y_utm = proj_latlon_to_stac.transform(lon, lat)\n",
    "x_min, x_max = x_utm - self.buffer, x_utm + self.buffer\n",
    "y_min, y_max = y_utm - self.buffer, y_utm + self.buffer\n",
    "\n",
    "# convert buffer bounds back to latlon 4326\n",
    "proj_stac_to_latlon = pyproj.Transformer.from_crs(\n",
    "    stac_crs, 4326, always_xy=True\n",
    ")\n",
    "x_min, y_min = proj_stac_to_latlon.transform(x_min, y_min)\n",
    "x_max, y_max = proj_stac_to_latlon.transform(x_max, y_max)\n",
    "\n",
    "# do stackstac call in 4326. Rescale must be True (default).\n",
    "# NOTE: rough converted resolution... How to get this to be exact??\n",
    "rough_latlon_resolution = (1 / 111111) * self.resolution\n",
    "xarray = stackstac.stack(\n",
    "    stac_item,\n",
    "    assets=self.bands,\n",
    "    epsg=4326,\n",
    "    resolution=rough_latlon_resolution,\n",
    "    bounds_latlon=[x_min, y_min, x_max, y_max],\n",
    "    dtype=np.uint8,\n",
    "    fill_value=0,\n",
    "    # rescale=False,\n",
    "    # snap_bounds=False\n",
    ")\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "\n",
    "# def parse_args():\n",
    "#     \"\"\"Parses arguments for the script.\"\"\"\n",
    "\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\n",
    "#         \"--admin-level\",\n",
    "#         action=\"store\",\n",
    "#         default=\"village\",\n",
    "#         help=\"Adminstatrative level to use for the shapefiles. Options: 'village', 'subdistrict', 'district', or 'state.\",\n",
    "#     )\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     return args\n",
    "\n",
    "def main():\n",
    "    \"\"\"Preprocess SHRUG keys (rural and urban) by adding shapes and saving to file.\"\"\"\n",
    "\n",
    "    # args = parse_args()\n",
    "    # level = args.admin_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select list of columns to drop from the data so only features and target are left\n",
    "# shrug_key_cols = [\n",
    "#     \"shrid\",\n",
    "#     \"pc11_s_id\",\n",
    "#     \"pc11_d_id\",\n",
    "#     \"pc11_sd_id\",\n",
    "#     \"pc11_tv_id\",\n",
    "#     \"tv_name\",\n",
    "#     \"geometry\",\n",
    "#     \"geometry_village\"\n",
    "#     \"geometry_subdistrict\",\n",
    "# ]\n",
    "# geo_cols = [\"Lat\", \"Lon\"] + shrug_key_cols\n",
    "\n",
    "# shrug_secc_cols = [\n",
    "#     \"shrid\",\n",
    "#     \"secc_inc_cultiv_share\",\n",
    "#     \"nco2d_cultiv_share\",\n",
    "#     \"secc_cons_pc_rural\",\n",
    "#     \"secc_cons_pc_urban\",\n",
    "#     \"secc_pov_rate_rural\",\n",
    "#     \"secc_pov_rate_urban\",\n",
    "#     \"secc_pov_rate_tend_rural\",\n",
    "#     \"secc_pov_rate_tend_urban\",\n",
    "#     \"num_members_mean_rural\",\n",
    "#     \"num_members_mean_urban\",\n",
    "# ]\n",
    "# shrug_secc_cols.remove(y_name)\n",
    "\n",
    "# cols_to_drop = shrug_secc_cols + geo_cols\n",
    "\n",
    "# X = gdf_clean.drop(cols_to_drop + [y_name], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notnull = ~(mosaiks_features[\"1000\"].isnull())*1\n",
    "\n",
    "f, ax = plt.subplots(1,1)\n",
    "notnull.cumsum().plot(ax=ax)\n",
    "ax.plot([0,96167],[0,96167],c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load temp files, combine, and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "filepaths = sorted(glob.glob(mosaiks_path+\"2021_*.parquet.gzip\"))\n",
    "\n",
    "filepaths\n",
    "\n",
    "temp = pd.read_parquet(\n",
    "    \"/home/jovyan/ds_nudge_up/data/01_preprocessed/mosaiks_features/2021_3km_v4000_L8_60000__0_to_36166.parquet.gzip\"\n",
    ")\n",
    "temp.index = range(60000, 96167)\n",
    "temp.to_parquet(\n",
    "    \"/home/jovyan/ds_nudge_up/data/01_preprocessed/mosaiks_features/2021_3km_v4000_L8_60000_to_96166.parquet.gzip\", \n",
    "    compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '2021_3km_v4000_L8_0_to_96166.parquet.gzip'\n",
    "\n",
    "l_dfs = []\n",
    "for filepath in filepaths:\n",
    "    l_dfs.append(pd.read_parquet(filepath))\n",
    "\n",
    "mosaiks_features = pd.concat(l_dfs, axis=0)\n",
    "\n",
    "mosaiks_features.to_parquet(mosaiks_path+filename, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter points with buffer\n",
    "\n",
    "states = gpd.read_file(f\"{DATA_ROOT}/00_raw/SHRUG/geometries_shrug-v1.5.samosa-open-polygons-shp/state.shp\")\n",
    "states['zero_column'] = 0\n",
    "country = states.dissolve(by='zero_column')\n",
    "BUFFER_DISTANCE = 0.005\n",
    "\n",
    "\n",
    "def filter_points_with_buffer(points_gdf, shape, buffer_distance):\n",
    "    # This buffer ensures that no points are take at the border\n",
    "    # which would lead to duplication with neighboring countries\n",
    "\n",
    "    return points_gdf[points_gdf.within(shape.unary_union.buffer(buffer_distance))]\n",
    "\n",
    "points_gdf = filter_points_with_buffer(points_gdf, country, BUFFER_DISTANCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MOSAIKS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom-made mosaiks features\n",
    "# data_label = \"3km_v1024_L8\"\n",
    "# filename = 'mosaiks_2013_L8_0.015b_all_points.parquet.gzip'\n",
    "\n",
    "# data_label = \"1km_v1024_L8\"\n",
    "# filename = 'mosaiks_2013_L8_0.005b_all_points.parquet.gzip'\n",
    "\n",
    "# lat_name, lon_name = \"lat\", \"lon\"\n",
    "\n",
    "# Load data\n",
    "# mosaiks_features = pd.read_parquet(mosaiks_path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OR using old data downloaded from the online API\n",
    "# data_label = \"old_v4000\"\n",
    "# filename = \"mosaiks_downloaded_old_features_rounded.csv\"\n",
    "# lat_name, lon_name = \"Lat\", \"Lon\"\n",
    "\n",
    "# # Load data\n",
    "# mosaiks_features = pd.read_csv(mosaiks_path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiks_features_gdf = load_mosaiks_data(\"INDIA_SHRUG_Mosaiks_features.csv\")\n",
    "# mosaiks_features_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiks_features_gdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed SHRUG keys with shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrug_key_geoms = load_gdf(\"01_preprocessed/SHRUG/shrug_pc11r_key_with_shapes\", \"shrug_pc11r_key_with_shapes.shp\")\n",
    "# shrug_key_geoms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use SHRUG shapes to add `shrid`s to MOSAIKS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaiks_features_gdf = add_shrid_to_mosaiks(mosaiks_features_gdf, shrug_key_geoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import SHRUG SECC (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path.cwd().parent / \"data\" / \"00_raw\" / \"SHRUG\" / \"shrug-v1.5.samosa-secc-csv\" / \"shrug_secc.csv\"\n",
    "shrug_secc = pd.read_csv(file_path)\n",
    "# shrug_secc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrug_secc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match target to features using `shrid`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_mosaiks_and_secc(mosaiks_features_gdf, shrug_secc)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nudge_up",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (default, Nov 15 2020, 06:25:35) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "142c193bf060635deeb675579e1db6ca9d9f29c8a237f64acc594fb64723fb97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
